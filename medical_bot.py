import requests
from bs4 import BeautifulSoup
import json
from datetime import datetime
import pandas as pd

class MedicalContentBot:
    def __init__(self):
        self.articles = []
        
    def search_medical_sources(self, keywords):
        """Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± Ù…Ù†Ø§Ø¨Ø¹ Ù¾Ø²Ø´Ú©ÛŒ"""
        print("ğŸ” Ø¯Ø± Ø­Ø§Ù„ Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± Ù…Ù†Ø§Ø¨Ø¹ Ù¾Ø²Ø´Ú©ÛŒ...")
        
        # Ù…Ù†Ø§Ø¨Ø¹ Ù…Ø¹ØªØ¨Ø± Ù¾Ø²Ø´Ú©ÛŒ
        sources = [
            "https://pubmed.ncbi.nlm.nih.gov/",
            "https://www.medicalnewstoday.com/",
            "https://www.webmd.com/"
        ]
        
        # Ù†ØªØ§ÛŒØ¬ Ù†Ù…ÙˆÙ†Ù‡ (ÙØ¹Ù„Ø§Ù‹)
        sample_articles = [
            {
                "title": "New advances in diabetes treatment 2024",
                "summary": "Latest research on type 2 diabetes medications",
                "source": "PubMed",
                "url": "https://example.com/1",
                "category": "endocrinology",
                "date": "2024-01-20"
            },
            {
                "title": "Breakthrough in cancer immunotherapy",
                "summary": "New immunotherapy approaches for lung cancer",
                "source": "Medical News Today", 
                "url": "https://example.com/2",
                "category": "oncology",
                "date": "2024-01-19"
            }
        ]
        
        return sample_articles
    
    def translate_content(self, text):
        """ØªØ±Ø¬Ù…Ù‡ Ù…Ø­ØªÙˆØ§ (Ù†Ø³Ø®Ù‡ Ø³Ø§Ø¯Ù‡)"""
        # Ø§ÛŒÙ†Ø¬Ø§ Ø¨Ø¹Ø¯Ø§Ù‹ Ø§Ø² API ØªØ±Ø¬Ù…Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
        translations = {
            "New advances in diabetes treatment 2024": "Ù¾ÛŒØ´Ø±ÙØªâ€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ø¯Ø± Ø¯Ø±Ù…Ø§Ù† Ø¯ÛŒØ§Ø¨Øª Û²Û°Û²Û´",
            "Breakthrough in cancer immunotherapy": "ØªØ­ÙˆÙ„ Ø¯Ø± Ø§ÛŒÙ…Ù†ÛŒâ€ŒØ¯Ø±Ù…Ø§Ù†ÛŒ Ø³Ø±Ø·Ø§Ù†"
        }
        return translations.get(text, text)
    
    def save_to_json(self, articles):
        """Ø°Ø®ÛŒØ±Ù‡ Ù…Ù‚Ø§Ù„Ø§Øª Ø¯Ø± ÙØ§ÛŒÙ„ JSON"""
        filename = f"medical_articles_{datetime.now().strftime('%Y%m%d_%H%M')}.json"
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(articles, f, ensure_ascii=False, indent=2)
        return filename
    
    def update_website_content(self, articles):
        """Ø¢Ù¾Ø¯ÛŒØª Ù…Ø­ØªÙˆØ§ÛŒ Ø³Ø§ÛŒØª"""
        print("ğŸ”„ Ø¯Ø± Ø­Ø§Ù„ Ø¢Ù¾Ø¯ÛŒØª Ø³Ø§ÛŒØª...")
        
        # Ø³Ø§Ø®Øª HTML Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ù…Ù‚Ø§Ù„Ø§Øª
        html_content = ""
        for article in articles:
            html_content += f'''
            <div class="article-card">
                <span class="article-category">{article['category']}</span>
                <h3>{article['title_fa']}</h3>
                <p>{article['summary_fa']}</p>
                <small>Ù…Ù†Ø¨Ø¹: {article['source']} - {article['date']}</small>
            </div>
            '''
        
        print("âœ… Ù…Ø­ØªÙˆØ§ÛŒ HTML Ø¢Ù…Ø§Ø¯Ù‡ Ø´Ø¯")
        return html_content

def main():
    print("ğŸš€ Ø±Ø¨Ø§Øª ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§ÛŒ Ù¾Ø²Ø´Ú©ÛŒ ÙØ¹Ø§Ù„ Ø´Ø¯!")
    
    bot = MedicalContentBot()
    
    # Û±. Ø¬Ø³ØªØ¬Ùˆ
    keywords = ["diabetes", "cancer", "cardiology"]
    articles = bot.search_medical_sources(keywords)
    
    # Û². ØªØ±Ø¬Ù…Ù‡
    for article in articles:
        article['title_fa'] = bot.translate_content(article['title'])
        article['summary_fa'] = bot.translate_content(article['summary'])
    
    # Û³. Ø°Ø®ÛŒØ±Ù‡
    output_file = bot.save_to_json(articles)
    
    # Û´. ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§ÛŒ Ø³Ø§ÛŒØª
    html_content = bot.update_website_content(articles)
    
    print(f"âœ… Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ø§Ù…Ù„ Ø´Ø¯!")
    print(f"ğŸ“Š ØªØ¹Ø¯Ø§Ø¯ Ù…Ù‚Ø§Ù„Ø§Øª: {len(articles)}")
    print(f"ğŸ’¾ ÙØ§ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ: {output_file}")
    print(f"ğŸ“ Ù…Ø­ØªÙˆØ§ÛŒ HTML ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡")

if __name__ == "__main__":
    main()
