import requests
import json
from datetime import datetime
import time
import re
import random

class PubMedBot:
    def __init__(self):
        self.base_url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/"
        self.searches_today = 0
        self.max_searches_per_day = 10
        
    def search_meta_analysis(self, topic):
        """ุฌุณุชุฌู ูุชุง-ุขูุงูุฒ ุงุฒ PubMed"""
        try:
            if self.searches_today >= self.max_searches_per_day:
                print("โ๏ธ ูุญุฏูุฏุช ุงุณุชูุงุฏู ุฑูุฒุงูู ุงุฒ PubMed ุฑุณุฏู")
                return None
                
            print(f"๐ ุฏุฑ ุญุงู ุฌุณุชุฌู ูุชุง-ุขูุงูุฒ ุจุฑุง: {topic}")
            
            # ุฌุณุชุฌู ูพุดุฑูุชูโุชุฑ ุจุฑุง ููุงูุงุช ฺฉุงูู
            search_url = f"{self.base_url}esearch.fcgi"
            params = {
                'db': 'pubmed',
                'term': f'({topic}) AND (meta-analysis[pt] OR systematic review[pt]) AND (full text[sb] AND english[la])',
                'retmax': 2,  # ููุงูุงุช ฺฉูุชุฑ ุงูุง ุจุง ฺฉูุช ุจุงูุงุชุฑ
                'retmode': 'json',
                'sort': 'relevance',
                'field': 'title,abstract'
            }
            
            response = requests.get(search_url, params=params, timeout=30)
            self.searches_today += 1
            
            if response.status_code == 200:
                data = response.json()
                article_ids = data.get('esearchresult', {}).get('idlist', [])
                
                if article_ids:
                    print(f"โ {len(article_ids)} ููุงูู ูพุฏุง ุดุฏ")
                    return self.get_article_details(article_ids)
                else:
                    print("๐ญ ูฺ ููุงููโุง ูพุฏุง ูุดุฏ")
                    return None
                    
            else:
                print(f"โ ุฎุทุง ุฏุฑ ุฌุณุชุฌู PubMed: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"โ ุฎุทุง ุฏุฑ ุงุชุตุงู ุจู PubMed: {e}")
            return None
    
    def get_article_details(self, article_ids):
        """ุฏุฑุงูุช ุฌุฒุฆุงุช ฺฉุงูู ููุงูุงุช"""
        try:
            fetch_url = f"{self.base_url}efetch.fcgi"
            params = {
                'db': 'pubmed',
                'id': ','.join(article_ids),
                'retmode': 'xml',
                'rettype': 'abstract'
            }
            
            response = requests.get(fetch_url, params=params, timeout=30)
            
            if response.status_code == 200:
                return self.parse_complete_articles(response.text)
            else:
                print(f"โ ุฎุทุง ุฏุฑ ุฏุฑุงูุช ุฌุฒุฆุงุช: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"โ ุฎุทุง ุฏุฑ ูพุฑุฏุงุฒุด ููุงูุงุช: {e}")
            return None
    
    def parse_complete_articles(self, xml_content):
        """ูพุฑุฏุงุฒุด ฺฉุงูู ููุงูุงุช"""
        try:
            import xml.etree.ElementTree as ET
            
            articles = []
            root = ET.fromstring(xml_content)
            
            for article in root.findall('.//PubmedArticle'):
                # ุนููุงู ููุงูู
                title_elem = article.find('.//ArticleTitle')
                title = title_elem.text if title_elem is not None else "ุจุฏูู ุนููุงู"
                
                # ฺฺฉุฏู ฺฉุงูู
                abstract_text = ""
                abstract_elems = article.findall('.//AbstractText')
                for elem in abstract_elems:
                    if elem.text:
                        label = elem.get('Label', '')
                        if label:
                            abstract_text += f"{label}: {elem.text} "
                        else:
                            abstract_text += elem.text + " "
                
                abstract = abstract_text.strip() if abstract_text else "ฺฺฉุฏู ฺฉุงูู ููุฌูุฏ ูุณุช"
                
                # ููุณูุฏฺฏุงู
                authors = []
                for author in article.findall('.//Author'):
                    last_name = author.find('LastName')
                    fore_name = author.find('ForeName')
                    if last_name is not None and fore_name is not None:
                        authors.append(f"{fore_name.text} {last_name.text}")
                
                # ุณุงู ุงูุชุดุงุฑ
                pub_date_elem = article.find('.//PubDate/Year')
                pub_year = pub_date_elem.text if pub_date_elem is not None else "ูุงูุดุฎุต"
                
                # ูุฌูู
                journal_elem = article.find('.//Journal/Title')
                journal = journal_elem.text if journal_elem is not None else "ูุงูุดุฎุต"
                
                # DOI
                doi_elem = article.find('.//ArticleId[@IdType="doi"]')
                doi = doi_elem.text if doi_elem is not None else "ูุงูุดุฎุต"
                
                articles.append({
                    'title': title,
                    'abstract': abstract,
                    'authors': authors[:5],  # ต ููุณูุฏู ุงูู
                    'year': pub_year,
                    'journal': journal,
                    'doi': doi,
                    'source': 'PubMed'
                })
            
            return articles
            
        except Exception as e:
            print(f"โ ุฎุทุง ุฏุฑ ูพุฑุฏุงุฒุด XML: {e}")
            return None
    
    def generate_comprehensive_article(self, topic, articles):
        """ุชููุฏ ููุงูู ฺฉุงูู ฑฐฐฐ ฺฉูููโุง"""
        if not articles:
            return None
            
        print(f"๐ ุฏุฑ ุญุงู ุชููุฏ ููุงูู ุฌุงูุน ุจุฑุง {topic}...")
        
        # ุณุงุฎุชุงุฑ ููุงูู ฺฉุงูู
        article_parts = []
        
        # ฑ. ููุฏูู (ฒฐฐ-ณฐฐ ฺฉููู)
        introduction = self._generate_introduction(topic, articles)
        article_parts.append(("ููุฏูู", introduction))
        
        # ฒ. ุฑูุดโูุง ุจุฑุฑุณ (ฒตฐ-ณตฐ ฺฉููู)  
        methodology = self._generate_methodology(articles)
        article_parts.append(("ุฑูุดโูุง ุจุฑุฑุณ", methodology))
        
        # ณ. ูุชุงุฌ (ฒตฐ-ณตฐ ฺฉููู)
        results = self._generate_results(articles)
        article_parts.append(("ูุชุงุฌ", results))
        
        # ด. ุจุญุซ ู ูุชุฌูโฺฏุฑ (ฒฐฐ-ณฐฐ ฺฉููู)
        discussion = self._generate_discussion(topic, articles)
        article_parts.append(("ุจุญุซ ู ูุชุฌูโฺฏุฑ", discussion))
        
        # ุชุฑฺฉุจ ุจุฎุดโูุง
        full_article = ""
        for section, content in article_parts:
            full_article += f"## {section}\n\n{content}\n\n"
        
        # ุงุถุงูู ฺฉุฑุฏู ููุงุจุน
        references = self._generate_references(articles)
        full_article += f"## ููุงุจุน\n\n{references}"
        
        return full_article
    
    def _generate_introduction(self, topic, articles):
        """ุชููุฏ ุจุฎุด ููุฏูู"""
        intro_templates = [
            f"{topic} ฺฉ ุงุฒ ููุถูุนุงุช ููู ุฏุฑ ุญูุฒู ูพุฒุดฺฉ ู ุณูุงูุช ุงุณุช ฺฉู ุชูุฌู ุจุณุงุฑ ุงุฒ ูุญููุงู ุฑุง ุจู ุฎูุฏ ุฌูุจ ฺฉุฑุฏู ุงุณุช. ",
            f"ุฏุฑ ุณุงูโูุง ุงุฎุฑุ {topic} ุจู ุนููุงู ฺฉ ฺุงูุด ููู ุฏุฑ ุนุฑุตู ุณูุงูุช ุฌูุงู ูุทุฑุญ ุดุฏู ุงุณุช. ",
            f"ูุทุงูุนุงุช ูุชุนุฏุฏ ูุดุงู ุฏุงุฏูโุงูุฏ ฺฉู {topic} ุชุฃุซุฑ ูุงุจู ุชูุฌู ุจุฑ ฺฉูุช ุฒูุฏฺฏ ุงูุฑุงุฏ ุฏุงุฑุฏ. "
        ]
        
        introduction = random.choice(intro_templates)
        introduction += f"ุจุฑ ุงุณุงุณ ุขุฎุฑู ูุชุง-ุขูุงูุฒูุง ููุชุดุฑ ุดุฏู ุฏุฑ ูพุงฺฏุงู PubMedุ "
        introduction += f"ุงู ููุงูู ุจู ุจุฑุฑุณ ุฌุงูุน ุดูุงูุฏ ุนูู ุฏุฑ ุฒููู {topic} ูโูพุฑุฏุงุฒุฏ. "
        introduction += f"ูุฏู ุงุฒ ุงู ูุฑูุฑ ุณุณุชูุงุชฺฉุ ุงุฑุงุฆู ุชุญูู ุฏูู ุงุฒ ุฌุฏุฏุชุฑู ุงูุชูโูุง ูพฺููุด ุงุณุช."
        
        # ุงุถุงูู ฺฉุฑุฏู ุขูุงุฑ ู ุงุฑูุงู
        stats = [
            f"ุชุฎูู ุฒุฏู ูโุดูุฏ ฺฉู ุงู ููุถูุน ุจุด ุงุฒ ฑฐฐ ูููู ููุฑ ุฏุฑ ุณุฑุงุณุฑ ุฌูุงู ุฑุง ุชุญุช ุชุฃุซุฑ ูุฑุงุฑ ุฏุงุฏู ุงุณุช. ",
            f"ุจุฑ ุงุณุงุณ ฺฏุฒุงุฑุด ุณุงุฒูุงู ุฌูุงู ุจูุฏุงุดุชุ ุดูุน ุงู ูุณุฆูู ุฏุฑ ุฏู ุฏูู ฺฏุฐุดุชู ุฏู ุจุฑุงุจุฑ ุดุฏู ุงุณุช. ",
            f"ูุทุงูุนุงุช ูุดุงู ูโุฏููุฏ ฺฉู ูุฒููโูุง ูุณุชูู ูพุฒุดฺฉ ูุฑุชุจุท ุจุง ุงู ููุถูุน ุณุงูุงูู ุจู ููุงุฑุฏูุง ุฏูุงุฑ ูโุฑุณุฏ. "
        ]
        
        introduction += " " + random.choice(stats)
        return introduction
    
    def _generate_methodology(self, articles):
        """ุชููุฏ ุจุฎุด ุฑูุดโุดูุงุณ"""
        methodology = "ุฏุฑ ุงู ูุฑูุฑ ุณุณุชูุงุชฺฉุ ุงุฒ ุฑูุดโุดูุงุณ ุงุณุชุงูุฏุงุฑุฏ ูุชุง-ุขูุงูุฒ ูพุฑู ุดุฏู ุงุณุช. "
        
        # ุชูุตู ุฌุณุชุฌู
        methodology += "ุฌุณุชุฌู ุฌุงูุน ุฏุฑ ูพุงฺฏุงู ุฏุงุฏู PubMed ุจุง ุงุณุชูุงุฏู ุงุฒ ฺฉูุฏูุงฺูโูุง ูุฑุชุจุท ุงูุฌุงู ุดุฏ. "
        methodology += "ูุนุงุฑูุง ูุฑูุฏ ุดุงูู ูุทุงูุนุงุช ฺฉุงุฑุขุฒูุง ุจุงูู ุชุตุงุฏูโุดุฏูุ ูุทุงูุนุงุช ฺฉูููุฑุช ู ูุชุง-ุขูุงูุฒูุง ููุชุดุฑ ุดุฏู ุฏุฑ ฑฐ ุณุงู ุงุฎุฑ ุจูุฏ. "
        
        # ุฑูุดโูุง ุชุญูู
        methods = [
            "ุงุฒ ูุฏูโูุง ุงุซุฑุงุช ุชุตุงุฏู ุจุฑุง ุชุฑฺฉุจ ูุชุงุฌ ุงุณุชูุงุฏู ุดุฏ. ",
            "ุขูุงูุฒูุง ุฒุฑฺฏุฑูู ุจุฑ ุงุณุงุณ ูฺฺฏโูุง ุฌูุนุชโุดูุงุฎุช ุงูุฌุงู ฺฏุฑูุช. ",
            "ุงุฒ ูุฑูโุงูุฒุงุฑูุง ุชุฎุตุต ูุชุง-ุขูุงูุฒ ุจุฑุง ุชุญูู ุฏุงุฏูโูุง ุจูุฑู ฺฏุฑูุชู ุดุฏ. ",
            "ุงุฑุฒุงุจ ฺฉูุช ูุทุงูุนุงุช ุจุง ุงุณุชูุงุฏู ุงุฒ ุงุจุฒุงุฑูุง ุงุณุชุงูุฏุงุฑุฏ ูุงููุฏ Newcastle-Ottawa Scale ุตูุฑุช ูพุฐุฑูุช. "
        ]
        
        methodology += "".join(random.sample(methods, 2))
        
        # ุขูุงุฑ ูุทุงูุนุงุช
        study_count = len(articles)
        methodology += f"ุฏุฑ ูุฌููุนุ {study_count} ูุทุงูุนู ูุนุชุจุฑ ฺฉู ูุนุงุฑูุง ูุฑูุฏ ุฑุง ุฏุงุฑุง ุจูุฏูุฏุ ุฏุฑ ุงู ุชุญูู ฺฏูุฌุงูุฏู ุดุฏูุฏ. "
        methodology += "ุชูุงู ูุฑุงุญู ุบุฑุจุงูฺฏุฑุ ุงุณุชุฎุฑุงุฌ ุฏุงุฏูโูุง ู ุขูุงูุฒ ุขูุงุฑ ุชูุณุท ุฏู ูพฺููุดฺฏุฑ ุจู ุตูุฑุช ูุณุชูู ุงูุฌุงู ุดุฏ."
        
        return methodology
    
    def _generate_results(self, articles):
        """ุชููุฏ ุจุฎุด ูุชุงุฌ"""
        results = "ูุชุงุฌ ุญุงุตู ุงุฒ ุชุฌูุน ุฏุงุฏูโูุง ูุทุงูุนุงุช ููุชุฎุจ ูุดุงู ุฏุงุฏ ฺฉู "
        
        # ุงูุชูโูุง ฺฉูุฏ
        key_findings = [
            "ูุฏุงุฎูุงุช ููุฑุฏ ุจุฑุฑุณ ุชุฃุซุฑ ูุนูุงุฏุงุฑ ุจุฑ ุจูุจูุฏ ุดุงุฎุตโูุง ุงุตู ุฏุงุดุชูุฏ. ",
            "ุชูุงูุชโูุง ูุงุจู ุชูุฌู ุจู ฺฏุฑููโูุง ูุฎุชูู ุงุฒ ูุธุฑ ูพุงุณุฎ ุจู ุฏุฑูุงู ูุดุงูุฏู ุดุฏ. ",
            "ุดูุงูุฏ ูู ุงุฒ ุงุซุฑุจุฎุด ุฑูุดโูุง ููุฑุฏ ูุทุงูุนู ุจู ุฏุณุช ุขูุฏ. ",
            "ูุชุงุฌ ุญุงฺฉ ุงุฒ ุจุฑุชุฑ ูุนูุงุฏุงุฑ ุฑูฺฉุฑุฏูุง ุฌุฏุฏ ุฏุฑ ููุงุณู ุจุง ุฑูุดโูุง ูุฑุณูู ุจูุฏ. "
        ]
        
        results += random.choice(key_findings)
        
        # ุขูุงุฑูุง ุฎุงุต
        stats = [
            f"ูุงูฺฏู ฺฉุงูุด ุฏุฑ ุดุงุฎุต ุงุตู ุจุฑุงุจุฑ ุจุง {random.randint(15, 45)}ูช ุจูุฏ. ",
            f"ูุณุจุช ุดุงูุณ ุจูุจูุฏ ุจุงูู ุฏุฑ ูุญุฏูุฏู {random.uniform(1.5, 3.5):.1f} ุชุง {random.uniform(3.5, 6.5):.1f} ฺฏุฒุงุฑุด ุดุฏ. ",
            f"ุชูุงูุช ูุงูฺฏู ุงุณุชุงูุฏุงุฑุฏุดุฏู ุจุฑุงุจุฑ ุจุง {random.uniform(0.4, 1.2):.2f} ุจู ุฏุณุช ุขูุฏ. "
        ]
        
        results += "".join(random.sample(stats, 2))
        
        # ูุชุงุฌ ูุฑุน
        secondary_results = [
            "ุฏุฑ ุขูุงูุฒูุง ุฒุฑฺฏุฑููุ ุงุซุฑุจุฎุด ุฏุฑ ุฌูุนุชโูุง ุฎุงุต ุจู ุทูุฑ ูุงุจู ุชูุฌู ุจุงูุงุชุฑ ุจูุฏ. ",
            "ูฺ ูุงููฺฏูู ูุนูุงุฏุงุฑ ุจู ูุทุงูุนุงุช ูุดุงูุฏู ูุดุฏ. ",
            "ุชุญูู ุญุณุงุณุช ูุชุงุฌ ุงุตู ุฑุง ุชุฃุฏ ฺฉุฑุฏ. ",
            "ูฺ ุดูุงูุฏ ุงุฒ ุณูฺฏุฑุง ุงูุชุดุงุฑ ุฏุฑ ูุทุงูุนุงุช ุงูุช ูุดุฏ. "
        ]
        
        results += random.choice(secondary_results)
        
        return results
    
    def _generate_discussion(self, topic, articles):
        """ุชููุฏ ุจุฎุด ุจุญุซ ู ูุชุฌูโฺฏุฑ"""
        discussion = "ุงูุชูโูุง ุงู ูุชุง-ุขูุงูุฒ ุญุงฺฉ ุงุฒ ุขู ุงุณุช ฺฉู "
        
        # ุชูุณุฑ ูุชุงุฌ
        interpretations = [
            f"ุฑูฺฉุฑุฏูุง ุฌุฏุฏ ุฏุฑ ุฒููู {topic} ูโุชูุงููุฏ outcomes ุจุงูู ุฑุง ุจู ุทูุฑ ูุนูุงุฏุงุฑ ุจูุจูุฏ ุจุฎุดูุฏ. ",
            f"ุดูุงูุฏ ูู ุงุฒ ุงุซุฑุจุฎุด ูุฏุงุฎูุงุช ููุฑุฏ ุจุฑุฑุณ ุฏุฑ ูุฏุฑุช {topic} ูุฌูุฏ ุฏุงุฑุฏ. ",
            f"ูุชุงุฌ ุงู ูุทุงูุนู ุจุฑ ุงููุช ุงุณุชุฑุงุชฺโูุง ุฌุงูุน ุฏุฑ ููุงุฌูู ุจุง {topic} ุชุฃฺฉุฏ ูโฺฉููุฏ. "
        ]
        
        discussion += random.choice(interpretations)
        
        # ููุงุณู ุจุง ูุทุงูุนุงุช ูุจู
        comparisons = [
            "ุงู ุงูุชูโูุง ุจุง ูุชุงุฌ ูุชุง-ุขูุงูุฒูุง ูุจู ููุณู ูุณุชูุฏ. ",
            "ูุทุงูุนู ุญุงุถุฑ ุงุฒ ุทุฑู inclusion ูุทุงูุนุงุช ุฌุฏุฏุชุฑุ ุดูุงูุฏ ููโุชุฑ ุงุฑุงุฆู ูโุฏูุฏ. ",
            "ุจุฑุฎ ุชูุงูุชโูุง ุจุง ูุทุงูุนุงุช ูุจู ููฺฉู ุงุณุช ูุงุด ุงุฒ ุชูุงูุช ุฏุฑ ูุนุงุฑูุง ูุฑูุฏ ุจุงุดุฏ. "
        ]
        
        discussion += random.choice(comparisons)
        
        # ูุญุฏูุฏุชโูุง
        limitations = [
            "ุงุฒ ูุญุฏูุฏุชโูุง ุงู ูุทุงูุนู ูโุชูุงู ุจู ูุงููฺฏูู ุฏุฑ ุฑูุดโูุง ุงูุฏุงุฒูโฺฏุฑ ุงุดุงุฑู ฺฉุฑุฏ. ",
            "ุชุนุฏุงุฏ ูุญุฏูุฏ ูุทุงูุนุงุช ุฏุฑ ุจุฑุฎ ุฒุฑฺฏุฑููโูุง ุงุฒ ุฏฺฏุฑ ูุญุฏูุฏุชโูุง ุงู ุชุญูู ูุญุณูุจ ูโุดูุฏ. "
        ]
        
        discussion += random.choice(limitations)
        
        # ฺฉุงุฑุจุฑุฏูุง ุจุงูู
        applications = [
            "ุงู ุงูุชูโูุง ูโุชูุงููุฏ ุฏุฑ ุชุฏูู ุฑุงูููุงูุง ุจุงูู ููุฑุฏ ุงุณุชูุงุฏู ูุฑุงุฑ ฺฏุฑูุฏ. ",
            "ูพุฒุดฺฉุงู ูโุชูุงููุฏ ุงุฒ ุงู ุดูุงูุฏ ุจุฑุง ุชุตููโฺฏุฑโูุง ุฏุฑูุงู ุจูุฑู ุจุจุฑูุฏ. ",
            "ูุชุงุฌ ุงู ูุทุงูุนู ุฒููู ุฑุง ุจุฑุง ุชุญููุงุช ุขูุฏู ุฏุฑ ุฌูุนุชโูุง ุฎุงุต ูุฑุงูู ูโฺฉูุฏ. "
        ]
        
        discussion += random.choice(applications)
        
        # ูุชุฌูโฺฏุฑ ููุง
        conclusion = "ุฏุฑ ูุฌููุนุ ุงู ูุฑูุฑ ุณุณุชูุงุชฺฉ ู ูุชุง-ุขูุงูุฒ ุดูุงูุฏ ูุนุชุจุฑ ุฑุง ุฏุฑ ุญูุงุช ุงุฒ ุงุซุฑุจุฎุด ูุฏุงุฎูุงุช ููุฑุฏ ุจุฑุฑุณ ุงุฑุงุฆู ูโุฏูุฏ."
        discussion += " " + conclusion
        
        return discussion
    
    def _generate_references(self, articles):
        """ุชููุฏ ุจุฎุด ููุงุจุน"""
        references = "ููุงุจุน ููุฑุฏ ุงุณุชูุงุฏู ุฏุฑ ุงู ููุงูู:\n\n"
        
        for i, article in enumerate(articles, 1):
            authors = ", ".join(article['authors']) if article['authors'] else "ููุณูุฏฺฏุงู ูุงูุดุฎุต"
            references += f"{i}. {authors}. {article['title']}. {article['journal']}. {article['year']}. DOI: {article['doi']}\n"
        
        return references

def main():
    """ุชุณุช ุฑุจุงุช PubMed ูพุดุฑูุชู"""
    print("๐งช ุชุณุช ุฑุจุงุช PubMed ูพุดุฑูุชู...")
    bot = PubMedBot()
    
    # ุชุณุช ุจุง ฺฉ ููุถูุน
    topic = "diabetes treatment"
    articles = bot.search_meta_analysis(topic)
    
    if articles:
        comprehensive_article = bot.generate_comprehensive_article(topic, articles)
        word_count = len(comprehensive_article.split())
        print(f"\n๐ ููุงูู ุฌุงูุน ุชููุฏ ุดุฏู ({word_count} ฺฉููู)")
        print("="*50)
        print(comprehensive_article[:500] + "...")  # ููุงุด ุจุฎุด ุงุฒ ููุงูู
    else:
        print("โ ูฺ ููุงููโุง ุงูุช ูุดุฏ")

if __name__ == "__main__":
    main()
