import requests
import json
from datetime import datetime
import time
import re

class PubMedBot:
    def __init__(self):
        self.base_url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/"
        self.searches_today = 0
        self.max_searches_per_day = 10  # Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø§Ø³ØªÙØ§Ø¯Ù‡
        
    def search_meta_analysis(self, topic):
        """Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…ØªØ§-Ø¢Ù†Ø§Ù„ÛŒØ² Ø§Ø² PubMed"""
        try:
            if self.searches_today >= self.max_searches_per_day:
                print("âš ï¸ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø±ÙˆØ²Ø§Ù†Ù‡ Ø§Ø² PubMed Ø±Ø³ÛŒØ¯Ù‡")
                return None
                
            print(f"ğŸ” Ø¯Ø± Ø­Ø§Ù„ Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…ØªØ§-Ø¢Ù†Ø§Ù„ÛŒØ² Ø¨Ø±Ø§ÛŒ: {topic}")
            
            # Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± PubMed
            search_url = f"{self.base_url}esearch.fcgi"
            params = {
                'db': 'pubmed',
                'term': f'({topic}) AND (meta-analysis[pt] OR systematic review[pt])',
                'retmax': 3,  # ÙÙ‚Ø· Û³ Ù…Ù‚Ø§Ù„Ù‡
                'retmode': 'json',
                'sort': 'relevance'
            }
            
            response = requests.get(search_url, params=params, timeout=30)
            self.searches_today += 1
            
            if response.status_code == 200:
                data = response.json()
                article_ids = data.get('esearchresult', {}).get('idlist', [])
                
                if article_ids:
                    print(f"âœ… {len(article_ids)} Ù…Ù‚Ø§Ù„Ù‡ Ù¾ÛŒØ¯Ø§ Ø´Ø¯")
                    return self.get_article_details(article_ids)
                else:
                    print("ğŸ“­ Ù‡ÛŒÚ† Ù…Ù‚Ø§Ù„Ù‡â€ŒØ§ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯")
                    return None
                    
            else:
                print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¬Ø³ØªØ¬ÙˆÛŒ PubMed: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§ØªØµØ§Ù„ Ø¨Ù‡ PubMed: {e}")
            return None
    
    def get_article_details(self, article_ids):
        """Ø¯Ø±ÛŒØ§ÙØª Ø¬Ø²Ø¦ÛŒØ§Øª Ù…Ù‚Ø§Ù„Ø§Øª"""
        try:
            fetch_url = f"{self.base_url}efetch.fcgi"
            params = {
                'db': 'pubmed',
                'id': ','.join(article_ids),
                'retmode': 'xml'
            }
            
            response = requests.get(fetch_url, params=params, timeout=30)
            
            if response.status_code == 200:
                return self.parse_articles_xml(response.text)
            else:
                print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¬Ø²Ø¦ÛŒØ§Øª: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ù‚Ø§Ù„Ø§Øª: {e}")
            return None
    
    def parse_articles_xml(self, xml_content):
        """Ù¾Ø±Ø¯Ø§Ø²Ø´ XML Ù…Ù‚Ø§Ù„Ø§Øª"""
        try:
            import xml.etree.ElementTree as ET
            
            articles = []
            root = ET.fromstring(xml_content)
            
            for article in root.findall('.//PubmedArticle'):
                # Ø¹Ù†ÙˆØ§Ù† Ù…Ù‚Ø§Ù„Ù‡
                title_elem = article.find('.//ArticleTitle')
                title = title_elem.text if title_elem is not None else "Ø¨Ø¯ÙˆÙ† Ø¹Ù†ÙˆØ§Ù†"
                
                # Ú†Ú©ÛŒØ¯Ù‡ Ù…Ù‚Ø§Ù„Ù‡
                abstract_elem = article.find('.//AbstractText')
                abstract = abstract_elem.text if abstract_elem is not None else "Ú†Ú©ÛŒØ¯Ù‡ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª"
                
                # Ù†ÙˆÛŒØ³Ù†Ø¯Ú¯Ø§Ù†
                authors = []
                for author in article.findall('.//Author'):
                    last_name = author.find('LastName')
                    fore_name = author.find('ForeName')
                    if last_name is not None and fore_name is not None:
                        authors.append(f"{fore_name.text} {last_name.text}")
                
                # Ø³Ø§Ù„ Ø§Ù†ØªØ´Ø§Ø±
                pub_date_elem = article.find('.//PubDate/Year')
                pub_year = pub_date_elem.text if pub_date_elem is not None else "Ù†Ø§Ù…Ø´Ø®Øµ"
                
                articles.append({
                    'title': title,
                    'abstract': abstract[:500] + "..." if len(abstract) > 500 else abstract,  # Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø·ÙˆÙ„
                    'authors': authors[:3],  # ÙÙ‚Ø· Û³ Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡ Ø§ÙˆÙ„
                    'year': pub_year,
                    'source': 'PubMed'
                })
            
            return articles
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ XML: {e}")
            return None
    
    def generate_summary(self, topic, articles):
        """ØªÙˆÙ„ÛŒØ¯ Ø®Ù„Ø§ØµÙ‡ Ø§Ø² Ù…Ù‚Ø§Ù„Ø§Øª"""
        if not articles:
            return None
            
        print(f"ğŸ“ Ø¯Ø± Ø­Ø§Ù„ ØªÙˆÙ„ÛŒØ¯ Ø®Ù„Ø§ØµÙ‡ Ø¨Ø±Ø§ÛŒ {topic}...")
        
        summary = f"Ø¨Ø± Ø§Ø³Ø§Ø³ {len(articles)} Ù…Ø·Ø§Ù„Ø¹Ù‡ Ù…ØªØ§-Ø¢Ù†Ø§Ù„ÛŒØ² Ø§Ø² PubMed:\n\n"
        
        for i, article in enumerate(articles, 1):
            summary += f"ğŸ“„ Ù…Ø·Ø§Ù„Ø¹Ù‡ {i}:\n"
            summary += f"   Ø¹Ù†ÙˆØ§Ù†: {article['title']}\n"
            summary += f"   Ù†ÙˆÛŒØ³Ù†Ø¯Ú¯Ø§Ù†: {', '.join(article['authors']) if article['authors'] else 'Ù†Ø§Ù…Ø´Ø®Øµ'}\n"
            summary += f"   Ø³Ø§Ù„: {article['year']}\n"
            summary += f"   Ø®Ù„Ø§ØµÙ‡: {article['abstract']}\n\n"
        
        # Ù†Ú©Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ
        summary += "ğŸ’¡ Ù†Ú©Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ:\n"
        summary += "â€¢ Ø§ÛŒÙ† Ù…Ø·Ø§Ù„Ø¹Ø§Øª Ø¨Ø± Ø§Ø³Ø§Ø³ Ø´ÙˆØ§Ù‡Ø¯ Ø¹Ù„Ù…ÛŒ Ù…Ø¹ØªØ¨Ø± Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯\n"
        summary += "â€¢ Ù…ØªØ§-Ø¢Ù†Ø§Ù„ÛŒØ²Ù‡Ø§ Ù…Ø¹ØªØ¨Ø±ØªØ±ÛŒÙ† Ø³Ø·Ø­ Ø´ÙˆØ§Ù‡Ø¯ Ù¾Ø²Ø´Ú©ÛŒ Ù‡Ø³ØªÙ†Ø¯\n"
        summary += "â€¢ Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨ÛŒØ´ØªØ± Ø¨Ø§ Ù¾Ø²Ø´Ú© Ø®ÙˆØ¯ Ù…Ø´ÙˆØ±Øª Ú©Ù†ÛŒØ¯\n"
        
        return summary

def main():
    """ØªØ³Øª Ø±Ø¨Ø§Øª PubMed"""
    print("ğŸ§ª ØªØ³Øª Ø±Ø¨Ø§Øª PubMed...")
    bot = PubMedBot()
    
    # ØªØ³Øª Ø¨Ø§ ÛŒÚ© Ù…ÙˆØ¶ÙˆØ¹
    topic = "diabetes treatment"
    articles = bot.search_meta_analysis(topic)
    
    if articles:
        summary = bot.generate_summary(topic, articles)
        print(f"\nğŸ“Š Ø®Ù„Ø§ØµÙ‡ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡:\n{summary}")
    else:
        print("âŒ Ù‡ÛŒÚ† Ù…Ù‚Ø§Ù„Ù‡â€ŒØ§ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯")

if __name__ == "__main__":
    main()
